{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_utilities import *\n",
    "from keras_utilities.models.vgg16 import Vgg16\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PROD = False\n",
    "\n",
    "if not PROD:\n",
    "    dataset = 'sample'\n",
    "else:\n",
    "    dataset = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Data Around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Fisheries\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Fisheries/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis.ipynb                  sample_submission_stg2.csv.zip  test_stg2.7z\n",
      "\u001b[0m\u001b[01;34msample\u001b[0m/                         \u001b[01;34mtest_stg1\u001b[0m/                      \u001b[01;34mtrain\u001b[0m/\n",
      "sample_submission_stg1.csv.zip  test_stg1.zip                   train.zip\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mALB\u001b[0m/  \u001b[01;34mBET\u001b[0m/  \u001b[01;34mDOL\u001b[0m/  \u001b[01;34mLAG\u001b[0m/  \u001b[01;34mNoF\u001b[0m/  \u001b[01;34mOTHER\u001b[0m/  \u001b[01;34mSHARK\u001b[0m/  \u001b[01;34mYFT\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -R /home/ubuntu/Fisheries/sample/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_data_sample('train', 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mALB\u001b[0m/  \u001b[01;34mBET\u001b[0m/  \u001b[01;34mDOL\u001b[0m/  \u001b[01;34mLAG\u001b[0m/  \u001b[01;34mNoF\u001b[0m/  \u001b[01;34mOTHER\u001b[0m/  \u001b[01;34mSHARK\u001b[0m/  \u001b[01;34mYFT\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mALB\u001b[0m/  \u001b[01;34mBET\u001b[0m/  \u001b[01;34mDOL\u001b[0m/  \u001b[01;34mLAG\u001b[0m/  \u001b[01;34mNoF\u001b[0m/  \u001b[01;34mOTHER\u001b[0m/  \u001b[01;34mSHARK\u001b[0m/  \u001b[01;34mYFT\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls sample/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719\n"
     ]
    }
   ],
   "source": [
    "! ls -l train/ALB/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427\n"
     ]
    }
   ],
   "source": [
    "! ls -l sample/ALB | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're good on counts, and seem to have successfully partitioned out 25% of the data to represent a training sample. Next, we have to work on coming up with a good validation set. Do the training set and validation sets come from different boats? If so, we might want to think about splitting out a few of the training boats to serve as validation boats.\n",
    "\n",
    "Maybe a new way to handle validation set creation is to allow two types of partitioning:\n",
    "\n",
    "1. A random percentage of the training data\n",
    "2. Some subset of the training data that meets a certain criteria (we could start with something simply based on the file's name)\n",
    "\n",
    "For cases where individual samples are totally iid we can use method 1, whereas if there is some relationship between examples (like some fish coming from the same boat, in this case) we can use method 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: a function for recursively creating a validation set from a training directory\n",
    "# for subdir in os.listdir('train'):\n",
    "#     train_path = 'train/' + subdir + '/'\n",
    "#     val_path = 'val' + '/' + subdir + '/'\n",
    "#     move_data_subset(train_path, val_path, subset_pct=.2, method='move')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "! ls -l val/ALB | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372\n"
     ]
    }
   ],
   "source": [
    "! ls -l train/ALB | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = gen.flow_from_directory(dataset, \n",
    "                                    target_size = (224,224), \n",
    "                                    batch_size = 32, \n",
    "                                    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 784 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = gen.flow_from_directory('val',\n",
    "                                  target_size = (224,224),\n",
    "                                  batch_size = 32,\n",
    "                                  class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.model.pop()\n",
    "for layer in mdl.model.layers: layer.trainable = False\n",
    "mdl.model.add(Dense(8, activation='softmax'))\n",
    "mdl.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "960/960 [==============================] - 965s - loss: 3.8568 - acc: 0.5437 - val_loss: 2.7484 - val_acc: 0.6480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb19b61e3d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.model.fit_generator(train_gen, \n",
    "                        samples_per_epoch = train_gen.nb_sample, \n",
    "                        nb_epoch = 1, \n",
    "                        validation_data = val_gen, \n",
    "                        nb_val_samples=val_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
