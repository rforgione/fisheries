{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_utilities import *\n",
    "from keras_utilities.models.vgg16 import Vgg16\n",
    "from keras_utilities.models.vgg16bn import Vgg16BN\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Input, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import bcolz\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PROD = True\n",
    "\n",
    "if not PROD:\n",
    "    dataset = 'sample'\n",
    "else:\n",
    "    dataset = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Data Around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Fisheries\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Fisheries/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis.ipynb  sample_submission_stg1.csv.zip  test_stg1.zip  train.zip\n",
      "\u001b[0m\u001b[01;34mdata\u001b[0m/           sample_submission_stg2.csv.zip  test_stg2.7z   \u001b[01;34mval\u001b[0m/\n",
      "\u001b[01;34msample\u001b[0m/         \u001b[01;34mtest_stg1\u001b[0m/                      \u001b[01;34mtrain\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mALB\u001b[0m/  \u001b[01;34mBET\u001b[0m/  \u001b[01;34mDOL\u001b[0m/  \u001b[01;34mLAG\u001b[0m/  \u001b[01;34mNoF\u001b[0m/  \u001b[01;34mOTHER\u001b[0m/  \u001b[01;34mSHARK\u001b[0m/  \u001b[01;34mYFT\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -R /home/ubuntu/Fisheries/sample/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_data_sample('train', 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mALB\u001b[0m/  \u001b[01;34mBET\u001b[0m/  \u001b[01;34mDOL\u001b[0m/  \u001b[01;34mLAG\u001b[0m/  \u001b[01;34mNoF\u001b[0m/  \u001b[01;34mOTHER\u001b[0m/  \u001b[01;34mSHARK\u001b[0m/  \u001b[01;34mYFT\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mALB\u001b[0m/  \u001b[01;34mBET\u001b[0m/  \u001b[01;34mDOL\u001b[0m/  \u001b[01;34mLAG\u001b[0m/  \u001b[01;34mNoF\u001b[0m/  \u001b[01;34mOTHER\u001b[0m/  \u001b[01;34mSHARK\u001b[0m/  \u001b[01;34mYFT\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls sample/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372\n"
     ]
    }
   ],
   "source": [
    "! ls -l train/ALB/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427\n"
     ]
    }
   ],
   "source": [
    "! ls -l sample/ALB | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're good on counts, and seem to have successfully partitioned out 25% of the data to represent a training sample. Next, we have to work on coming up with a good validation set. Do the training set and validation sets come from different boats? If so, we might want to think about splitting out a few of the training boats to serve as validation boats.\n",
    "\n",
    "Maybe a new way to handle validation set creation is to allow two types of partitioning:\n",
    "\n",
    "1. A random percentage of the training data\n",
    "2. Some subset of the training data that meets a certain criteria (we could start with something simply based on the file's name)\n",
    "\n",
    "For cases where individual samples are totally iid we can use method 1, whereas if there is some relationship between examples (like some fish coming from the same boat, in this case) we can use method 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: a function for recursively creating a validation set from a training directory\n",
    "# for subdir in os.listdir('train'):\n",
    "#     train_path = 'train/' + subdir + '/'\n",
    "#     val_path = 'val' + '/' + subdir + '/'\n",
    "#     move_data_subset(train_path, val_path, subset_pct=.2, method='move')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "! ls -l val/ALB | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372\n"
     ]
    }
   ],
   "source": [
    "! ls -l train/ALB | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2997 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = gen.flow_from_directory(dataset, \n",
    "                                    target_size = (224,224), \n",
    "                                    batch_size = 32, \n",
    "                                    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 784 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = gen.flow_from_directory('val',\n",
    "                                  target_size = (224,224),\n",
    "                                  batch_size = 32,\n",
    "                                  class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.model.pop()\n",
    "for layer in mdl.model.layers: layer.trainable = False\n",
    "mdl.model.add(Dense(8, activation='softmax'))\n",
    "mdl.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl.model.fit_generator(train_gen, \n",
    "#                         samples_per_epoch = train_gen.nb_sample, \n",
    "#                         nb_epoch = 1, \n",
    "#                         validation_data = val_gen, \n",
    "#                         nb_val_samples=val_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Computing Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is computationally intensive, so everything is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl = Vgg16BN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_types = map(lambda layer: type(layer), mdl.model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_dense_index = layer_types.index(Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_layers = mdl.model.layers[:first_dense_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_mdl = Sequential(new_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_data = conv_out_mdl.predict_generator(train_gen, train_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bcolz.carray(conv_out_data, rootdir='data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_conv_out_data = conv_out_mdl.predict_generator(val_gen, val_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bcolz.carray(val_conv_out_data, rootdir='data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mv data/train data/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_unflattened_layers = conv_out_mdl.layers[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_unflattened_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_unflattened = Sequential(conv_out_unflattened_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_unflattened_trn = conv_out_unflattened.predict_generator(train_gen, train_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_unflattened_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bcolz.carray(conv_out_unflattened_trn, rootdir='data/train_unflattened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_unflattened_val = conv_out_unflattened.predict_generator(val_gen, val_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out_unflattened_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bcolz.carray(conv_out_unflattened_val, rootdir='data/val_unflattened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\ttrain  train_unflattened  val  val_unflattened\n"
     ]
    }
   ],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single dense layer, just to get things up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = bcolz.open('data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2997, 25088)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(25088,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Dense(512, activation='relu')(inp)\n",
    "d2 = Dense(512, activation='relu')(d1)\n",
    "d3 = Dense(512, activation='relu')(d2)\n",
    "d4 = Dense(8, activation='softmax')(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_mdl = Model(input=inp, output=d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_mdl.compile(optimizer=Adam(lr=0.1), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2997/2997 [==============================] - 15s - loss: 4.9178    \n",
      "Epoch 2/10\n",
      "2997/2997 [==============================] - 15s - loss: 4.7600    \n",
      "Epoch 3/10\n",
      "2997/2997 [==============================] - 15s - loss: 4.7438    \n",
      "Epoch 4/10\n",
      "2997/2997 [==============================] - 15s - loss: 4.6910    \n",
      "Epoch 5/10\n",
      "2997/2997 [==============================] - 15s - loss: 4.6883    \n",
      "Epoch 6/10\n",
      "2997/2997 [==============================] - 15s - loss: 4.6664    \n",
      "Epoch 7/10\n",
      "2997/2997 [==============================] - 15s - loss: 4.6297    \n",
      "Epoch 8/10\n",
      "2997/2997 [==============================] - 15s - loss: nan    \n",
      "Epoch 9/10\n",
      "2997/2997 [==============================] - 15s - loss: nan    \n",
      "Epoch 10/10\n",
      "2997/2997 [==============================] - 15s - loss: nan    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6710c98450>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended_mdl.fit(x=trn, y=y, nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient explosionnnnnnnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: start with the weights from the vgg dense layers and fine tune those"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
